---
layout: post
title: Two Methods to Predict Stock Index
author: Chenlu Wang
date: 2019-08-03
---



<p style="text-align:justify">
The stock price is a typical time series column data (referred to as time series data), which will be affected by various complicated factors such as economic environment, government policies, and human operation. This paper takes the historical data of stock index as the research object and introduces two models that can be used to make stock index prediction: ARIMA model and LSTM model.
</p>

<!-- more -->

<p style="text-align:justify">
I first introduce the ARIMA model, which is a classic model in time series analysis. The dataset I am using comes from the Google Finance API, and I have done missing value processing. ARIMA (Auto-Regressive Integrated Moving Average) can be used to predict time series and is often used in demand forecasting and planning. However, if you start with a non-stationary time series, you first need to make a difference until you get a smooth sequence. ARIMA is the most common method in current time series analysis. It is a process of extracting long-term trend, fixed period and other information through differential operation, and transforming non-stationary sequence into the stationary sequence. If $\{x_t\}$ is a $ARIMA(p, d, q)$ model. $d$ means:$$\Delta^dx_t=\Delta^{d-1}(x_t-x_{t-1}):=w_t$$.And the formula of $\{w_t\}$ is $$w_t=\phi_1w_{t-1}+\phi_2w_{t-2}+\dots+\phi_qw_{t-q}+u_t+\psi_1u_{t-1}+\psi_2u_{t-2}+\dots+\psi_pu_{t-p}$$. And $\{u_t\}$ is a white noise.
</p>

<p style="text-align:justify">
In the prediction, I first made a difference to the original data. After the data looks stable, I draw their PACF and ACF maps. If the ACF graph cuts off after lag=q, then this q is the parameter q in the model. If the PACF graph cuts off after lag=p, then this p is the parameter p in the model. I use R to discuss the possible model AIC, AICC, BIC values, and I can find the appropriate parameters. Then I use the Yule-Walker algorithm to calculate the estimated value of the coefficient so that we can predict the subsequent stock parameters.
</p>

<p style="text-align:justify">
The LSTM algorithm is called Long short-term memory. It was first proposed by Sepp Hochreiter and JÃ¼rgen Schmidhuber in 1997. It is a specific form of RNN (Recurrent Neural Network), and RNN is a series of processes capable of processing time series data. The general term for neural networks. RNN can be interpreted merely as a neural network with time implications. However, RNNs encounter significant difficulties in dealing with long-term dependencies (nodes that are far apart in time series), because the calculation of the distance between nodes with far distances involves much multiplication of the Jacobian matrix, which will solve The problem of gradient disappearance or gradient expansion observed by many scholars and independently studied. LSTM is a particular RNN model proposed to solve this problem. The cleverness of LSTM is that by adding input gates, forgetting thresholds and outputting gates. The weight of the self-loop changed so that the integral scale at different times can dynamically change when the model parameters fixed, thus avoiding the gradient. The problem of disappearing or gradient expansion. The picture below is the result of my prediction of the stock index using LSTM.
</p>


<center>
<img src="/wclnarry.github.io/picture/11.png" alt="drawing" width="700"/>
</center>

<p style="text-align:justify">
Comparing the two models, the LSTM model performed better than ARIMA. The LSTM model belongs to the Algorithmic Modeling Culture. It only uses statistical methods when setting the activate functions and loss functions. I cannot summarize the specific mathematical formula from the LSTM model. The ARIMA model is a typical Data Modeling Culture, which can summarize specific mathematical formulas. When designing the training layers, LSTM includes many factors that affect the stock index such as economic factors, human factors, political factors and so on. However, the ARIMA model is mainly a time factor that weakens the influence of other factors. When I was using ARIMA model, I used the functions already in R, which means that I can control a small part. However, the LSTM model is different, and its training layers, activation function, initial value, etc. can be manually adjusted. However, the magnitude of the data required by the two models is entirely different. The amount of data required by the ARIMA model is significantly smaller than that of the LSTM model because ARIMA is more targeted. If the amount of data is small, the performance of the ARIMA model is likely to be much better than the LSTM.
</p>
